{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1b0db472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statistics import mean, median\n",
    "import sys\n",
    "import pprint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "922f4e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_ytest_lib = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d9d2bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_values(Y_data):\n",
    "    Y_t = []\n",
    "    for e in Y_data:\n",
    "        if e == 'passed':\n",
    "            Y_t.append(1)\n",
    "        else:\n",
    "            Y_t.append(0) \n",
    "    return Y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "892819ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_failures(df):\n",
    "    \n",
    "    results = df['tr_status'].tolist()\n",
    "    length = len(results)\n",
    "    verdict = ['keep']\n",
    "    prev = results[0]\n",
    "    \n",
    "    for i in range(1, length):\n",
    "        if results[i] == 0:\n",
    "            if prev == 0:\n",
    "                verdict.append('discard')\n",
    "                #print(i+1)\n",
    "            else:\n",
    "                verdict.append('keep')\n",
    "        else:\n",
    "            verdict.append('keep')\n",
    "        prev = results[i]\n",
    "    \n",
    "    df['verdict'] = verdict\n",
    "    df = df[ df['verdict'] == 'keep' ]\n",
    "    df.drop('verdict', inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b64d2018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_list(s):\n",
    "    if s == '[]':\n",
    "        return [0]\n",
    "    l = s[1:-1].split(', ')\n",
    "    l = [int(x) for x in l]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c514f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_versions(results):\n",
    "    version_dfs = []\n",
    "    \n",
    "    for i in range(1,11):\n",
    "        ver = results[ results['version']==i]\n",
    "        version_dfs.append(ver)\n",
    "    return version_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "68fb2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_delays(ci, y_test, batch_size):\n",
    "    \n",
    "    \n",
    "    y_test = output_values(y_test)\n",
    "    \n",
    "    sbs_list = []\n",
    "    missed = []\n",
    "    b = batch_size\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    while i < len(ci):\n",
    "\n",
    "        if ci[i] == 0:\n",
    "            if y_test[i] == 0:\n",
    "                sbs_list.append(0)\n",
    "\n",
    "            while len(missed) > 0:\n",
    "                ind = missed.pop()\n",
    "                sbs_list.append(i - ind)\n",
    "\n",
    "            b -= 1\n",
    "            if b == -1:\n",
    "                b = batch_size - 1\n",
    "\n",
    "        if ci[i] == 1:\n",
    "            if y_test[i] == 0:\n",
    "                missed.append(i)\n",
    "\n",
    "        i += 1\n",
    "    while len(missed) > 0:\n",
    "            sbs_list.append(i - missed.pop())\n",
    "    \n",
    "    return sbs_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dc481fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_result_collection(filename):\n",
    "    \n",
    "    global project_ytest_lib\n",
    "    \n",
    "    results = pd.read_csv(filename)\n",
    "    \n",
    "    projects = set(results['project'].tolist())\n",
    "    all_versions = pd.DataFrame()\n",
    "        \n",
    "    for p in projects:\n",
    "        \n",
    "        #getting project data\n",
    "        p_data = results[ results['project']==p]\n",
    "        pframe = pd.DataFrame()\n",
    "        \n",
    "        #splitting data into versions\n",
    "        versions = separate_versions(p_data)\n",
    "        \n",
    "        for start in range(0,10):\n",
    "            if len(versions[start]) > 0:\n",
    "                pframe = versions[start]\n",
    "                break\n",
    "        \n",
    "        #starting with the first version's project frame\n",
    "        for x in range(len(pframe)):\n",
    "            row = pframe.iloc[x]\n",
    "            \n",
    "            alg = row['algorithm']\n",
    "            b = row['batch_size']\n",
    "            conf = row['confidence']\n",
    "            \n",
    "            if p in project_ytest_lib:\n",
    "                y_test = project_ytest_lib[p]\n",
    "            else:\n",
    "                test_file = '../../data/full_data/' + p + '.csv'\n",
    "                y_test = pd.read_csv(test_file, usecols=['tr_build_id', 'tr_status'])\n",
    "                project_ytest_lib[p] = y_test\n",
    "                \n",
    "            \n",
    "            index_file = '../../data/project_data_pickles/' + p + '.csv_' + str(row['version']) + '_indexes.pkl'\n",
    "            with open(index_file, 'rb') as infile:\n",
    "                train_indexes = pickle.load(infile)\n",
    "                test_indexes = pickle.load(infile)\n",
    "            \n",
    "            ver_xtest = y_test [ y_test['tr_build_id'].isin(test_indexes)]\n",
    "            ver_ytest = ver_xtest['tr_status'].tolist()\n",
    "                \n",
    "            \n",
    "            final_batch_median = str_to_list(row['batch_median'])\n",
    "            final_ci = str_to_list(row['ci'])\n",
    "            final_proj_delays = get_project_delays(final_ci, ver_ytest, b)\n",
    "            \n",
    "            \n",
    "            #appending other frames to outer frame\n",
    "            for i in range(start+1,10):\n",
    "                next_ver = versions[i]\n",
    "                \n",
    "                #extracting corresponding outer row for each version\n",
    "                new_df = next_ver[ (next_ver['algorithm']==alg) & (next_ver['batch_size']==b) & (next_ver['confidence']==conf)]\n",
    "                \n",
    "                if len(new_df) > 0:\n",
    "                    new_row = new_df.iloc[0]\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                total_reqd_builds = (row['project_reqd_builds']*row['testall_size']) + (new_row['project_reqd_builds']*new_row['testall_size'])\n",
    "                total_missed_builds = (row['project_missed_builds']*row['testall_size']) + (new_row['project_missed_builds']*new_row['testall_size'])\n",
    "                total_saved_builds = (row['project_saved_builds']*row['testall_size']) + (new_row['project_saved_builds']*new_row['testall_size'])\n",
    "                total_size = row['testall_size'] + new_row['testall_size']\n",
    "                \n",
    "                row['project_reqd_builds'] = total_reqd_builds/total_size\n",
    "                row['project_missed_builds'] = total_missed_builds/total_size\n",
    "                row['project_saved_builds'] = total_saved_builds/total_size\n",
    "                row['testall_size'] = total_size\n",
    "                \n",
    "                index_file = '../../data/project_data_pickles/' + p + '.csv_' + str(new_row['version']) + '_indexes.pkl'\n",
    "                with open(index_file, 'rb') as infile:\n",
    "                    train_indexes = pickle.load(infile)\n",
    "                    test_indexes = pickle.load(infile)\n",
    "                            \n",
    "                ver_xtest = y_test [ y_test['tr_build_id'].isin(test_indexes)]\n",
    "                ver_ytest = ver_xtest['tr_status'].tolist()\n",
    "                \n",
    "                new_ci = str_to_list(new_row['ci'])\n",
    "                final_proj_delays.extend(get_project_delays(new_ci, ver_ytest, b))\n",
    "                final_batch_median.extend(str_to_list(new_row['batch_median']))\n",
    "                final_ci.extend(new_ci)\n",
    "                \n",
    "                row['project_delays'] = final_proj_delays\n",
    "                row['batch_median'] = final_batch_median\n",
    "                row['ci'] = final_ci\n",
    "                                            \n",
    "            pframe.iloc[x] = row\n",
    "        all_versions = all_versions.append(pframe)\n",
    "    \n",
    "    return all_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b6c55c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['../final_full_results.csv', '../heroku_results.csv','cvh_models.csv', 'lfs.csv', 'results1.csv', 'results2.csv', 'gradle_models.csv', 'rubinius_models.csv']\n",
    "file_root = '../version_results/'\n",
    "dfs = []\n",
    "\n",
    "for file in filenames[:2]:\n",
    "    dfs.append(start_result_collection(file_root+file))\n",
    "\n",
    "#combining dfs\n",
    "final_df = pd.DataFrame()\n",
    "final_df = dfs[0]\n",
    "\n",
    "for i in range(1, len(dfs)):\n",
    "    final_df = final_df.append(dfs[i])\n",
    "\n",
    "final_df.to_csv('combined_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cde01206",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.loc[:, ~final_df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3b3525b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('combined_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1eebde8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "short = pd.DataFrame()\n",
    "short = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0a3621d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "short.drop('ci', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "de03432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('short_combined_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad9a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03bf96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
