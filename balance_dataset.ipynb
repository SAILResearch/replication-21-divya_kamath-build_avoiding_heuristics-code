{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2330b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f63c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_balance(y_result):\n",
    "    pass_count = 0\n",
    "    fail_count = 0\n",
    "    length = len(y_result)\n",
    "    \n",
    "    for i in range(length):\n",
    "        if y_result[i] == 'passed':\n",
    "            pass_count += 1\n",
    "        else:\n",
    "            fail_count += 1\n",
    "    \n",
    "    if pass_count == 0:\n",
    "        return (0, fail_count*100/length)\n",
    "    \n",
    "    if fail_count == 0:\n",
    "        return (pass_count*100/length, 0)\n",
    "    \n",
    "    return (pass_count*100/length, fail_count*100/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3277253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(filename):\n",
    "    \n",
    "    csv_file = csv.reader(open(filename, 'r'))\n",
    "    \n",
    "    temp_data = []\n",
    "    final_data = []\n",
    "\n",
    "    for item in csv_file:\n",
    "        temp_data.append(item)\n",
    "\n",
    "    for i in range(len(temp_data[0])):\n",
    "        temp = []\n",
    "        for index in range(1, len(temp_data)):\n",
    "            temp.append(temp_data[index][i])\n",
    "        final_data.append(temp)\n",
    "\n",
    "    indices = range(len(final_data[3]))\n",
    "\n",
    "    #capture the metrics of source churn, test churn, file churn and team size in a list\n",
    "    src_churn = []\n",
    "    file_churn = []\n",
    "    test_churn = []\n",
    "    team_size = []\n",
    "    time_stamp = []\n",
    "    build_result = []\n",
    "    git_num_all_built_commits = []\n",
    "    gh_num_commits_on_files_touched = []\n",
    "    argument = []\n",
    "\n",
    "    for index in indices:\n",
    "        src_churn.append(float(final_data[23][index]))\n",
    "        file_churn.append(float(final_data[27][index]))\n",
    "        test_churn.append(float(final_data[24][index]))\n",
    "        team_size.append(float(final_data[14][index]))\n",
    "        time_stamp.append(datetime.strptime(final_data[41][index], \"%y-%m-%d %H:%M:%S\"))\n",
    "        \n",
    "        if final_data[42][index] == 'passed':\n",
    "            build_result.append(1)\n",
    "        else:\n",
    "            build_result.append(0)\n",
    "\n",
    "        argument.append([])\n",
    "\n",
    "    for index in range(len(src_churn)):\n",
    "        argument[index].append(src_churn[index])\n",
    "        argument[index].append(team_size[index])\n",
    "        argument[index].append(file_churn[index])\n",
    "        argument[index].append(test_churn[index])\n",
    "    \n",
    "    return np.array(argument), np.array(build_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fe96f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list = ['gradle', 'cloud_controller_ng', 'geoserver']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "590b13c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gradle... \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2014-03-05 01:06:23\n",
      "2014-05-04 01:06:23\n",
      "3.232217129171204\n",
      "(93.55234878722752, 6.44765121277249)\n",
      "(96.78456591639872, 3.215434083601286)\n",
      "\n",
      "\n",
      "311\n",
      "3257\n",
      "2014-05-04 01:06:23\n",
      "2014-07-03 01:06:23\n",
      "2.656744939891965\n",
      "(93.67353028946583, 6.326469710534169)\n",
      "(96.3302752293578, 3.669724770642202)\n",
      "\n",
      "\n",
      "218\n",
      "3351\n",
      "2014-09-01 01:06:23\n",
      "2014-10-31 01:06:23\n",
      "0.7633926395929649\n",
      "(93.72329937561616, 6.276700624383832)\n",
      "(94.48669201520913, 5.513307984790875)\n",
      "\n",
      "\n",
      "526\n",
      "3043\n",
      "Processing cloud_controller_ng... \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2013-01-17 20:55:32\n",
      "2013-03-18 20:55:32\n",
      "4.001904937475032\n",
      "(81.08581436077058, 18.914185639229423)\n",
      "(85.08771929824562, 14.912280701754385)\n",
      "\n",
      "\n",
      "114\n",
      "2284\n",
      "2013-03-18 20:55:32\n",
      "2013-05-17 20:55:32\n",
      "3.307703421718827\n",
      "(81.08945969884854, 18.91054030115146)\n",
      "(84.39716312056737, 15.602836879432624)\n",
      "\n",
      "\n",
      "141\n",
      "2258\n",
      "2013-05-17 20:55:32\n",
      "2013-07-16 20:55:32\n",
      "1.1774846086191815\n",
      "(81.22251539138082, 18.777484608619172)\n",
      "(82.4, 17.6)\n",
      "\n",
      "\n",
      "125\n",
      "2274\n",
      "2014-03-13 20:55:32\n",
      "2014-05-12 20:55:32\n",
      "0.9678658374708391\n",
      "(81.34761267291388, 18.65238732708612)\n",
      "(80.37974683544304, 19.620253164556964)\n",
      "\n",
      "\n",
      "158\n",
      "2241\n",
      "Processing geoserver... \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2013-09-28 16:19:56\n",
      "2013-11-27 16:19:56\n",
      "1.6528478444228725\n",
      "(52.5407005426739, 47.4592994573261)\n",
      "(54.193548387096776, 45.806451612903224)\n",
      "\n",
      "\n",
      "155\n",
      "2027\n",
      "2016-01-16 16:19:56\n",
      "2016-03-16 16:19:56\n",
      "1.033194887150266\n",
      "(52.5615763546798, 47.4384236453202)\n",
      "(53.59477124183007, 46.40522875816993)\n",
      "\n",
      "\n",
      "153\n",
      "2030\n"
     ]
    }
   ],
   "source": [
    "for project in project_list:\n",
    "    print('Processing {}... \\n\\n\\n\\n'.format(project))\n",
    "    \n",
    "    best_diff = 100\n",
    "    X = pd.read_csv('try_data/' + project + '.csv')\n",
    "    X['gh_build_started_at'] =  pd.to_datetime(X['gh_build_started_at'], format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    start_date = X['gh_build_started_at'].tolist()[0]\n",
    "    end_date = X['gh_build_started_at'].tolist()[-1]\n",
    "    \n",
    "    while start_date < end_date :\n",
    "        phase_end = start_date + datetime.timedelta(days = 60)\n",
    "        \n",
    "        test_data = X.loc[ (X['gh_build_started_at'] > start_date) & (X['gh_build_started_at'] < phase_end)]['tr_status'].tolist()\n",
    "        train_data = X.loc[ (X['gh_build_started_at'] < start_date) | (X['gh_build_started_at'] > phase_end)]['tr_status'].tolist()\n",
    "        \n",
    "        train_ev = measure_balance(train_data)\n",
    "        test_ev = measure_balance(test_data)\n",
    "        \n",
    "        diff = abs(train_ev[0] - test_ev[0])\n",
    "        if diff < best_diff:\n",
    "            best_diff = diff\n",
    "            print(start_date)\n",
    "            print(phase_end)\n",
    "            print(diff)\n",
    "            print(train_ev)\n",
    "            print(test_ev)\n",
    "            print('\\n')\n",
    "            \n",
    "            test_indexes = X.loc[ (X['gh_build_started_at'] > start_date) & (X['gh_build_started_at'] < phase_end)]['tr_build_id'].tolist()\n",
    "            train_indexes = X.loc[ (X['gh_build_started_at'] < start_date) | (X['gh_build_started_at'] > phase_end)]['tr_build_id'].tolist()\n",
    "            \n",
    "            print(len(test_indexes))\n",
    "            print(len(train_indexes))\n",
    "            \n",
    "            filename = project + '_indexes.pkl'\n",
    "            with open(filename, 'wb') as save_file:\n",
    "                pickle.dump(train_indexes, save_file)\n",
    "                pickle.dump(test_indexes, save_file)\n",
    "            \n",
    "        \n",
    "        start_date = phase_end\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc203ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
