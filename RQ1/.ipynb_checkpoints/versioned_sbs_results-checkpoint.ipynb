{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30d55864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from numpy import sqrt\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib import pyplot\n",
    "from statistics import median\n",
    "import pickle\n",
    "import csv\n",
    "import warnings\n",
    "import datetime\n",
    "import multiprocess\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db49d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(data):\n",
    "    data = sorted(data)\n",
    "    size = len(data)\n",
    "    if size % 2 == 0:  \n",
    "        median = (data[size // 2] + data[size // 2 - 1]) / 2\n",
    "        data[0] = median\n",
    "    if size % 2 == 1:  \n",
    "        median = data[(size - 1) // 2]\n",
    "        data[0] = median\n",
    "    return data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a583cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_failures(df):\n",
    "    \n",
    "    results = df['tr_status'].tolist()\n",
    "    length = len(results)\n",
    "    verdict = ['keep']\n",
    "    prev = results[0]\n",
    "    \n",
    "    for i in range(1, length):\n",
    "        if results[i] == 0:\n",
    "            if prev == 0:\n",
    "                verdict.append('discard')\n",
    "                #print(i+1)\n",
    "            else:\n",
    "                verdict.append('keep')\n",
    "        else:\n",
    "            verdict.append('keep')\n",
    "        prev = results[i]\n",
    "    \n",
    "    df['verdict'] = verdict\n",
    "    df = df[ df['verdict'] == 'keep' ]\n",
    "    df.drop('verdict', inplace=True, axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32d711ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_values(Y_data):\n",
    "    Y_t = []\n",
    "    for e in Y_data:\n",
    "        if e == 'passed':\n",
    "            Y_t.append(1)\n",
    "        else:\n",
    "            Y_t.append(0) \n",
    "    return Y_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ca1154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(project_path, first_failures=True):\n",
    "    columns = ['tr_build_id', 'git_num_all_built_commits', 'git_diff_src_churn', 'git_diff_test_churn', 'gh_diff_files_modified', 'tr_status']\n",
    "    df = pd.read_csv(project_path, usecols = columns)\n",
    "    df['tr_status'] = output_values(df['tr_status'])\n",
    "    if first_failures:\n",
    "        df = get_first_failures(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "459b87bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbs(p_name):\n",
    "    \n",
    "    p = p_name\n",
    "    result_file = 'version_results/' + p_name.split('.')[0] + '_sbs_predictions.csv'\n",
    "    fileroot = '../../RQ2-Models/' + p_name.split('.')[0] + '_models/'\n",
    "    \n",
    "    pframe = pd.DataFrame()\n",
    "    test_file = get_data('../data/full_data/' + p_name, first_failures=False)\n",
    "    \n",
    "    for i in range(1,11):\n",
    "        ver = i\n",
    "        \n",
    "        #retrieve the indexes\n",
    "        filename = '../data/project_data_pickles/' + p_name + '_' + str(i) + '_indexes.pkl'\n",
    "        with open(filename, 'rb') as save_file:\n",
    "            train_build_ids = pickle.load(save_file)\n",
    "            test_build_ids = pickle.load(save_file)\n",
    "        \n",
    "        \n",
    "        #form the test df\n",
    "        X_test = test_file [ test_file['tr_build_id'].isin(test_build_ids)] \n",
    "        y_test = X_test['tr_status'].tolist()\n",
    "        \n",
    "        X_test.drop('tr_status', inplace=True, axis=1)\n",
    "        X_test.drop('tr_build_id', inplace=True, axis=1)\n",
    "        \n",
    "        \n",
    "        #retrieve the model\n",
    "        if len(y_test) > 0:        \n",
    "            filename = fileroot + 'rq2_' + p_name.split('.')[0] + '_' + str(i) + '_best_model.pkl'\n",
    "            model_file = open(filename, 'rb')\n",
    "            forest = pickle.load(model_file)\n",
    "        \n",
    "        else:\n",
    "            print('Not found for {}{}'.format(i, p_name))\n",
    "            continue\n",
    "        \n",
    "        y_pred = forest.predict(X_test)\n",
    "        \n",
    "        verframe = pd.DataFrame()\n",
    "        verframe['Build_Result'] = y_pred\n",
    "        verframe['Actual_Result'] = y_test\n",
    "        \n",
    "        pframe = pframe.append(verframe)\n",
    "    \n",
    "    pframe.to_csv(result_file)\n",
    "    return pframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6db168e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(pframe, project):\n",
    "    \n",
    "    if pframe is None:\n",
    "        return []\n",
    "    \n",
    "    actual_results = pframe['Actual_Result'].tolist()\n",
    "    pred_results = pframe['Build_Result'].tolist()\n",
    "    \n",
    "    first_failure = 0\n",
    "    ci = []\n",
    "\n",
    "    total_builds = len(actual_results)\n",
    "    sbs_builds = 0\n",
    "    \n",
    "    #SBS Algorithm\n",
    "    for i in range(len(actual_results)):\n",
    "\n",
    "        #If first failure is already found, continue building until actual build pass is seen\n",
    "        if first_failure == 1:\n",
    "            ci.append(0)\n",
    "            sbs_builds += 1\n",
    "\n",
    "            if actual_results[i] == 1:\n",
    "                #actual build pass is seen, switch to prediction\n",
    "                first_failure = 0\n",
    "            else:\n",
    "                first_failure = 1\n",
    "        else:\n",
    "            #we're in prediction state, if predicted to skip, we skip\n",
    "            if pred_results[i] == 1:\n",
    "                ci.append(1)\n",
    "            else:\n",
    "                #if predicted to fail, we switch to determine state and set first_failure to True\n",
    "                ci.append(0)\n",
    "                sbs_builds += 1\n",
    "                first_failure = 1-actual_results[i]\n",
    "\n",
    "\n",
    "    total_builds = len(ci)\n",
    "    actual_builds = ci.count(0)\n",
    "    saved_builds = 100*ci.count(1)/total_builds\n",
    "    reqd_builds = 100*ci.count(0)/total_builds\n",
    "    \n",
    "    if sbs_builds != actual_builds:\n",
    "        print('PROBLEM!!')\n",
    "    \n",
    "    #computing delay\n",
    "    delay_indexes = []\n",
    "    built_indexes = []\n",
    "    \n",
    "    for i in range(len(ci)):\n",
    "        if ci[i] == 0:\n",
    "            built_indexes.append(i)\n",
    "        else:\n",
    "            if actual_results[i] == 0:\n",
    "                delay_indexes.append(i)\n",
    "    \n",
    "    bp = 0\n",
    "    mp = 0\n",
    "    temp_delay = 0\n",
    "    total_delay = 0\n",
    "    \n",
    "    delay_list = []\n",
    "    while bp < len(built_indexes):\n",
    "        while mp < len(delay_indexes) and delay_indexes[mp] < built_indexes[bp]:\n",
    "            temp_delay = built_indexes[bp] - delay_indexes[mp]\n",
    "            total_delay += temp_delay\n",
    "            delay_list.append(temp_delay)\n",
    "            mp += 1\n",
    "        bp += 1\n",
    "\n",
    "    while mp < len(delay_indexes):\n",
    "        temp_delay = total_builds - delay_indexes[mp]\n",
    "        total_delay += temp_delay\n",
    "        delay_list.append(temp_delay)\n",
    "        mp += 1\n",
    "    \n",
    "    for mp in delay_indexes:\n",
    "        if mp in built_indexes:\n",
    "            delay_list.append(0)    \n",
    "    \n",
    "    \n",
    "    skips = []\n",
    "    flag = 1\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(pred_results)):\n",
    "        \n",
    "        if flag == 0:\n",
    "            \n",
    "            count += 1\n",
    "            if pred_results[i] == 0:\n",
    "                count -= 1\n",
    "                flag = 1-flag\n",
    "      \n",
    "                skips.append(count)\n",
    "                count = 0\n",
    "\n",
    "        else:\n",
    "\n",
    "            if pred_results[i] == 1:\n",
    "                if actual_results[i] == 0:\n",
    "                    count += 1\n",
    "                    flag = 0\n",
    "  \n",
    "    if flag == 0:\n",
    "        skips.append(count)\n",
    "\n",
    "    delay = [total_delay]    \n",
    "    lines = []\n",
    "    \n",
    "    for alg in algorithms:\n",
    "        for b in batch_sizes:\n",
    "            if alg == 'BATCH4':\n",
    "                if b != 4:\n",
    "                    continue\n",
    "            \n",
    "            if alg == 'BATCHSTOP4':\n",
    "                if b < 4:\n",
    "                    continue\n",
    "            \n",
    "            lines.append([project, alg, b, saved_builds, reqd_builds, len(ci), skips, delay_list, median(delay_list)])\n",
    "    \n",
    "    return lines   \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a407381",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = ['heroku.csv', 'rails.csv', 'gradle.csv', 'jruby.csv', 'metasploit-framework.csv', 'cloudify.csv', 'vagrant.csv', 'rubinius.csv', 'open-build-service.csv', 'sonarqube.csv', 'loomio.csv', 'fog.csv', 'opal.csv', 'cloud_controller_ng.csv', 'puppet.csv', 'concerto.csv', 'sufia.csv', 'geoserver.csv', 'orbeon-forms.csv', 'graylog2-server.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8315229",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['BATCH4', 'BATCHSTOP4', 'BATCHBISECT']\n",
    "batch_sizes = [1, 2, 4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4188c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "18\n",
      "27\n",
      "36\n",
      "45\n",
      "54\n",
      "Not found for 1vagrant.csv\n",
      "Not found for 2vagrant.csv\n",
      "63\n",
      "72\n",
      "81\n",
      "90\n",
      "99\n",
      "108\n",
      "117\n",
      "126\n",
      "Not found for 1puppet.csv\n",
      "Not found for 2puppet.csv\n",
      "135\n",
      "144\n",
      "153\n",
      "162\n",
      "171\n",
      "Not found for 2graylog2-server.csv\n",
      "Not found for 3graylog2-server.csv\n",
      "Not found for 4graylog2-server.csv\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "for p in projects:\n",
    "    pframe = sbs(p)\n",
    "    lines.extend(get_results(pframe, p))\n",
    "    print(len(lines))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92e0e09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a07372f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lines, columns=['project', 'algorithm', 'batch_size', 'saved_builds', 'builds_reqd', 'testall_size', 'median_skips', 'delay_list', 'median_delay'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1106c065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>saved_builds</th>\n",
       "      <th>builds_reqd</th>\n",
       "      <th>testall_size</th>\n",
       "      <th>median_skips</th>\n",
       "      <th>delay_list</th>\n",
       "      <th>median_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heroku.csv</td>\n",
       "      <td>BATCH4</td>\n",
       "      <td>4</td>\n",
       "      <td>99.183085</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>2081</td>\n",
       "      <td>[4, 137, 186, 281, 146, 380, 85, 33, 4, 69, 85...</td>\n",
       "      <td>[4, 3, 137, 136, 135, 134, 133, 132, 131, 130,...</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heroku.csv</td>\n",
       "      <td>BATCHSTOP4</td>\n",
       "      <td>4</td>\n",
       "      <td>99.183085</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>2081</td>\n",
       "      <td>[4, 137, 186, 281, 146, 380, 85, 33, 4, 69, 85...</td>\n",
       "      <td>[4, 3, 137, 136, 135, 134, 133, 132, 131, 130,...</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heroku.csv</td>\n",
       "      <td>BATCHSTOP4</td>\n",
       "      <td>8</td>\n",
       "      <td>99.183085</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>2081</td>\n",
       "      <td>[4, 137, 186, 281, 146, 380, 85, 33, 4, 69, 85...</td>\n",
       "      <td>[4, 3, 137, 136, 135, 134, 133, 132, 131, 130,...</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heroku.csv</td>\n",
       "      <td>BATCHSTOP4</td>\n",
       "      <td>16</td>\n",
       "      <td>99.183085</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>2081</td>\n",
       "      <td>[4, 137, 186, 281, 146, 380, 85, 33, 4, 69, 85...</td>\n",
       "      <td>[4, 3, 137, 136, 135, 134, 133, 132, 131, 130,...</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heroku.csv</td>\n",
       "      <td>BATCHBISECT</td>\n",
       "      <td>1</td>\n",
       "      <td>99.183085</td>\n",
       "      <td>0.816915</td>\n",
       "      <td>2081</td>\n",
       "      <td>[4, 137, 186, 281, 146, 380, 85, 33, 4, 69, 85...</td>\n",
       "      <td>[4, 3, 137, 136, 135, 134, 133, 132, 131, 130,...</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>graylog2-server.csv</td>\n",
       "      <td>BATCHBISECT</td>\n",
       "      <td>1</td>\n",
       "      <td>99.857685</td>\n",
       "      <td>0.142315</td>\n",
       "      <td>2108</td>\n",
       "      <td>[86, 13, 1837]</td>\n",
       "      <td>[86, 83, 82, 76, 27, 13, 12, 1837, 1780, 1779,...</td>\n",
       "      <td>797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>graylog2-server.csv</td>\n",
       "      <td>BATCHBISECT</td>\n",
       "      <td>2</td>\n",
       "      <td>99.857685</td>\n",
       "      <td>0.142315</td>\n",
       "      <td>2108</td>\n",
       "      <td>[86, 13, 1837]</td>\n",
       "      <td>[86, 83, 82, 76, 27, 13, 12, 1837, 1780, 1779,...</td>\n",
       "      <td>797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>graylog2-server.csv</td>\n",
       "      <td>BATCHBISECT</td>\n",
       "      <td>4</td>\n",
       "      <td>99.857685</td>\n",
       "      <td>0.142315</td>\n",
       "      <td>2108</td>\n",
       "      <td>[86, 13, 1837]</td>\n",
       "      <td>[86, 83, 82, 76, 27, 13, 12, 1837, 1780, 1779,...</td>\n",
       "      <td>797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>graylog2-server.csv</td>\n",
       "      <td>BATCHBISECT</td>\n",
       "      <td>8</td>\n",
       "      <td>99.857685</td>\n",
       "      <td>0.142315</td>\n",
       "      <td>2108</td>\n",
       "      <td>[86, 13, 1837]</td>\n",
       "      <td>[86, 83, 82, 76, 27, 13, 12, 1837, 1780, 1779,...</td>\n",
       "      <td>797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>graylog2-server.csv</td>\n",
       "      <td>BATCHBISECT</td>\n",
       "      <td>16</td>\n",
       "      <td>99.857685</td>\n",
       "      <td>0.142315</td>\n",
       "      <td>2108</td>\n",
       "      <td>[86, 13, 1837]</td>\n",
       "      <td>[86, 83, 82, 76, 27, 13, 12, 1837, 1780, 1779,...</td>\n",
       "      <td>797.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 project    algorithm  batch_size  saved_builds  builds_reqd  \\\n",
       "0             heroku.csv       BATCH4           4     99.183085     0.816915   \n",
       "1             heroku.csv   BATCHSTOP4           4     99.183085     0.816915   \n",
       "2             heroku.csv   BATCHSTOP4           8     99.183085     0.816915   \n",
       "3             heroku.csv   BATCHSTOP4          16     99.183085     0.816915   \n",
       "4             heroku.csv  BATCHBISECT           1     99.183085     0.816915   \n",
       "..                   ...          ...         ...           ...          ...   \n",
       "175  graylog2-server.csv  BATCHBISECT           1     99.857685     0.142315   \n",
       "176  graylog2-server.csv  BATCHBISECT           2     99.857685     0.142315   \n",
       "177  graylog2-server.csv  BATCHBISECT           4     99.857685     0.142315   \n",
       "178  graylog2-server.csv  BATCHBISECT           8     99.857685     0.142315   \n",
       "179  graylog2-server.csv  BATCHBISECT          16     99.857685     0.142315   \n",
       "\n",
       "     testall_size                                       median_skips  \\\n",
       "0            2081  [4, 137, 186, 281, 146, 380, 85, 33, 4, 69, 85...   \n",
       "1            2081  [4, 137, 186, 281, 146, 380, 85, 33, 4, 69, 85...   \n",
       "2            2081  [4, 137, 186, 281, 146, 380, 85, 33, 4, 69, 85...   \n",
       "3            2081  [4, 137, 186, 281, 146, 380, 85, 33, 4, 69, 85...   \n",
       "4            2081  [4, 137, 186, 281, 146, 380, 85, 33, 4, 69, 85...   \n",
       "..            ...                                                ...   \n",
       "175          2108                                     [86, 13, 1837]   \n",
       "176          2108                                     [86, 13, 1837]   \n",
       "177          2108                                     [86, 13, 1837]   \n",
       "178          2108                                     [86, 13, 1837]   \n",
       "179          2108                                     [86, 13, 1837]   \n",
       "\n",
       "                                            delay_list  median_delay  \n",
       "0    [4, 3, 137, 136, 135, 134, 133, 132, 131, 130,...         132.0  \n",
       "1    [4, 3, 137, 136, 135, 134, 133, 132, 131, 130,...         132.0  \n",
       "2    [4, 3, 137, 136, 135, 134, 133, 132, 131, 130,...         132.0  \n",
       "3    [4, 3, 137, 136, 135, 134, 133, 132, 131, 130,...         132.0  \n",
       "4    [4, 3, 137, 136, 135, 134, 133, 132, 131, 130,...         132.0  \n",
       "..                                                 ...           ...  \n",
       "175  [86, 83, 82, 76, 27, 13, 12, 1837, 1780, 1779,...         797.0  \n",
       "176  [86, 83, 82, 76, 27, 13, 12, 1837, 1780, 1779,...         797.0  \n",
       "177  [86, 83, 82, 76, 27, 13, 12, 1837, 1780, 1779,...         797.0  \n",
       "178  [86, 83, 82, 76, 27, 13, 12, 1837, 1780, 1779,...         797.0  \n",
       "179  [86, 83, 82, 76, 27, 13, 12, 1837, 1780, 1779,...         797.0  \n",
       "\n",
       "[180 rows x 9 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fafaff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('version_sbs_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4353febc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5feb01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
